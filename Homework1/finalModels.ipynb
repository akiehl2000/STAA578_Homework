{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1 Final Models (Income Prediction)\n",
    "Adam Kiehl  \n",
    "4/10/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis packages\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import models\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn import compose\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csvs\n",
    "trainDF = pd.read_csv('./adult.csv')\n",
    "testDF = pd.read_csv('./adult_test.csv')\n",
    "\n",
    "# drop id column (wont be used for modeling)\n",
    "trainDF.drop('id', axis = 1, inplace = True)\n",
    "testIds = testDF['id']\n",
    "testDF.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric predictors and encode categorical predictors\n",
    "findNumPredictors = make_column_selector(dtype_include = int)\n",
    "findCatPredictors = make_column_selector(dtype_include = object)\n",
    "transform = make_column_transformer((MinMaxScaler(), findNumPredictors),\n",
    "                                    (OneHotEncoder(drop = 'first'), findCatPredictors))\n",
    "\n",
    "# get new column names\n",
    "colNames = transform.fit(trainDF).get_feature_names_out()\n",
    "\n",
    "# transform data\n",
    "modelDF = pd.DataFrame.sparse.from_spmatrix(transform.fit_transform(trainDF), columns = colNames)\n",
    "\n",
    "# get new column names\n",
    "colNames = transform.fit(testDF).get_feature_names_out()\n",
    "\n",
    "# transform data\n",
    "predDF = pd.DataFrame.sparse.from_spmatrix(transform.fit_transform(testDF), columns = colNames)\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(432023)\n",
    "\n",
    "# split data into predictors and response\n",
    "respTrain = modelDF['onehotencoder__income_>50K'].rename('income')\n",
    "modelDF.drop('onehotencoder__income_>50K', axis = 1, inplace = True)\n",
    "\n",
    "# split data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(modelDF, respTrain, test_size = 0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 85.94%\n"
     ]
    }
   ],
   "source": [
    "# tuned max features hyperparamter\n",
    "M = 22\n",
    "\n",
    "# fit random forest model\n",
    "model1 = RandomForestClassifier(max_features = M,\n",
    "                                n_estimators = 1000,\n",
    "                                random_state = 482023)\n",
    "model1.fit(X_train, y_train) \n",
    "\n",
    "# predict on validation set\n",
    "pred1 = model1.predict(X_valid)\n",
    "\n",
    "# calculate validation accuracy\n",
    "print(f\"Validation accuracy: {(np.mean(pred1 == np.array(y_valid)) * 100).round(2)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: early stopping\n",
      "204/204 [==============================] - 0s 2ms/step\n",
      "Validation accuracy: 85.77%\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(462023)\n",
    "tf.random.set_seed(482023)\n",
    "\n",
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# early stopping criteria\n",
    "earlyStop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "\n",
    "# tuned penalty hyperparameter\n",
    "PENALTY = 0.001\n",
    "\n",
    "# define model architecture\n",
    "model2 = models.Sequential([\n",
    "    Dense(512, activation = 'relu', kernel_regularizer = l2(PENALTY), input_shape = (X_train.shape[1], )),\n",
    "    Dense(256, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(128, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model2.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "# train model\n",
    "trained2 = model2.fit(X_train, \n",
    "                      to_categorical(y_train), \n",
    "                      epochs = EPOCHS, \n",
    "                      batch_size = 128, \n",
    "                      validation_split = 0.2,\n",
    "                      callbacks = earlyStop,\n",
    "                      verbose = 0)\n",
    "\n",
    "# predict on validation set\n",
    "pred2 = model2.predict(X_valid)\n",
    "\n",
    "# calculate validation accuracy\n",
    "print(f\"Validation accuracy: {((np.mean(pred2[:,1].round() == np.array(y_valid))) * 100).round(2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: early stopping\n",
      "204/204 [==============================] - 0s 2ms/step\n",
      "Validation accuracy: 85.51%\n"
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(462023)\n",
    "tf.random.set_seed(482023)\n",
    "\n",
    "# dropout rate\n",
    "RATE = 0.25\n",
    "\n",
    "# define model architecture\n",
    "model3 = models.Sequential([\n",
    "    Dense(512, activation = 'relu', input_shape = (X_train.shape[1], )),\n",
    "    Dropout(rate = RATE),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dropout(rate = RATE),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(rate = RATE),\n",
    "    Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model3.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "# train model\n",
    "trained3 = model3.fit(X_train, \n",
    "                      to_categorical(y_train), \n",
    "                      epochs = EPOCHS, \n",
    "                      batch_size = 128, \n",
    "                      validation_split = 0.2,\n",
    "                      callbacks = earlyStop,\n",
    "                      verbose = 0)\n",
    "\n",
    "# predict on validation set\n",
    "pred3 = model3.predict(X_valid)\n",
    "\n",
    "# calculate validation accuracy\n",
    "print(f\"Validation accuracy: {((np.mean(pred3[:,1].round() == np.array(y_valid))) * 100).round(2)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: early stopping\n",
      "509/509 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(462023)\n",
    "tf.random.set_seed(482023)\n",
    "\n",
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# early stopping criteria\n",
    "earlyStop = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 3)\n",
    "\n",
    "# tuned penalty hyperparameter\n",
    "PENALTY = 0.001\n",
    "\n",
    "# drop predictor not in test set\n",
    "modelDF.drop('onehotencoder__native_country_Holand-Netherlands', axis = 1, inplace = True)\n",
    "\n",
    "# define model architecture\n",
    "model = models.Sequential([\n",
    "    Dense(512, activation = 'relu', kernel_regularizer = l2(PENALTY), input_shape = (modelDF.shape[1], )),\n",
    "    Dense(256, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(128, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(2, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# train model\n",
    "trained = model.fit(modelDF, \n",
    "                    to_categorical(respTrain), \n",
    "                    epochs = EPOCHS, \n",
    "                    batch_size = 128, \n",
    "                    validation_split = 0.2,\n",
    "                    callbacks = earlyStop,\n",
    "                    verbose = 0)\n",
    "\n",
    "# predict on validation set\n",
    "pred = model.predict(predDF)\n",
    "pred = pred[:,1].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission data frame\n",
    "submission = pd.DataFrame({'id': testIds, 'income': np.where(pred, '>50K', '<=50K')})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
