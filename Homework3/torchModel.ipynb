{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial data transformation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# load training images\n",
    "train_data = torchvision.datasets.CIFAR10(root = '.', train = True, download = True, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\n",
    "\n",
    "# load test images\n",
    "test_data = torchvision.datasets.CIFAR10(root = '.', train = False, download = True, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False, num_workers = 2)\n",
    "\n",
    "# class names\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # model layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 'same')\n",
    "        self.conv2 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 'same')\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels = 32, kernel_size = 3, padding = 'same')\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.lin1 = nn.Linear(in_features = 32 * 16 * 16, out_features = 64)\n",
    "        self.lin2 = nn.Linear(in_features = 64, out_features = 10)\n",
    "\n",
    "        # activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = torch.flatten(x)\n",
    "        x = self.relu(self.lin1(x))\n",
    "        x = self.softmax(self.lin2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "EPOCHS = 10\n",
    "\n",
    "# initialize the model\n",
    "model = Net()\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr = 1e-4, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "torch.manual_seed(7212023)\n",
    "\n",
    "# metric tracking lists\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "# train the model\n",
    "for epoch in range(0, EPOCHS):\n",
    "    # load model state\n",
    "    if epoch != 0:\n",
    "        model.load_state_dict(torch.load(f'./ModelStates/income_mlp_{epoch - 1}.pkl')['model_state_dict'])\n",
    "    \n",
    "    # initialize variables to track running metrics\n",
    "    training_loss = 0.0\n",
    "    training_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # perform training step\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # update number of batches\n",
    "        num_batches += 1\n",
    "\n",
    "        # get inputs and labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(torch.argmax(outputs), labels)\n",
    "\n",
    "        # TODO: save training accuracy\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # save training loss\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    train_loss.append(training_loss / num_batches)\n",
    "    # TODO: save training accuracy\n",
    "\n",
    "    # initialize variables to track running metrics\n",
    "    validation_loss = 0.0\n",
    "    validation_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # perform validation step\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        # update number of batches\n",
    "        num_batches += 1\n",
    "\n",
    "        # get inputs and labels\n",
    "        inputs, lables = data\n",
    "        with torch.no_grad():\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(torch.argmax(outputs), labels)\n",
    "\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "            # TODO: save validation accuracy\n",
    "        \n",
    "    valid_loss.append(validation_loss / num_batches)\n",
    "    # TODO: save validation accuracy\n",
    "\n",
    "    # print the average loss for the epoch\n",
    "    print(f\"Epoch {epoch + 1} - Validation Loss: {np.round(validation_loss / num_batches, 7)}\")\n",
    "    # print(f\"Epoch {epoch + 1} - Validation Loss: {np.round(validation_loss / num_batches, 7)} | Validation Accuracy: {np.round(validation_acc / num_batches * 100, 2)}%\")\n",
    "\n",
    "    # save model state\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()},\n",
    "                './ModelStates/income_mlp_' + str(epoch) + '.pkl')\n",
    "\n",
    "# calculate training time\n",
    "end_time = time.time()\n",
    "print(f'Model Trained In {np.round(end_time - start_time, 2)} Seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
