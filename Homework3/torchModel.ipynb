{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU device\n",
    "gpu = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial data transformation\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# load training images\n",
    "train_data = torchvision.datasets.CIFAR10(root = '.', train = True, download = True, transform = transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\n",
    "\n",
    "# load test images\n",
    "test_data = torchvision.datasets.CIFAR10(root = '.', train = False, download = True, transform = transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False, num_workers = 2)\n",
    "\n",
    "# class names\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # model layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 128, kernel_size = 3, padding = 'same')\n",
    "        self.conv2 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 'same')\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels = 32, kernel_size = 3, padding = 'same')\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.lin1 = nn.Linear(in_features = 32 * 8 * 8, out_features = 64)\n",
    "        self.lin2 = nn.Linear(in_features = 64, out_features = 10)\n",
    "\n",
    "        # activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.lin1(x))\n",
    "        x = self.softmax(self.lin2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper():\n",
    "    def __init__(self, patience=3, min_diff=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_diff = min_diff\n",
    "        self.counter = 0\n",
    "        self.min_val_loss = np.inf\n",
    "    \n",
    "    def early_stop(self, val_loss):\n",
    "        if ((self.min_val_loss - validation_loss) / self.min_val_loss) < self.min_diff:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        elif validation_loss < self.min_val_loss:\n",
    "            self.min_val_loss = validation_loss\n",
    "            self.count = 0\n",
    "        \n",
    "        return False\n",
    "\n",
    "EarlyStop = EarlyStopper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# initialize the model\n",
    "model = Net()\n",
    "\n",
    "# utilize gpu\n",
    "model.to(gpu)\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr = 1e-3, weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "torch.manual_seed(7212023)\n",
    "\n",
    "# record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# metric tracking lists\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "# train the model\n",
    "print('Training CNN Model...')\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "    # load model state\n",
    "    if epoch != 0:\n",
    "        model.load_state_dict(torch.load(f'./ModelStates/income_mlp_{epoch - 1}.pkl')['model_state_dict'])\n",
    "    \n",
    "    # initialize variables to track running metrics\n",
    "    training_loss = 0.0\n",
    "    training_acc = 0.0\n",
    "\n",
    "    # perform training step\n",
    "    train_loop = tqdm(train_loader)\n",
    "    for batch in train_loop:\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get inputs and labels\n",
    "        inputs, labels = batch[0].to(gpu), batch[1].to(gpu)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # compute training loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # save training loss\n",
    "        training_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        # save training accuracy\n",
    "        training_acc += np.sum(torch.argmax(outputs, dim=1).cpu().numpy() == labels.cpu().numpy()) / len(train_loader)\n",
    "\n",
    "        # format progress bar\n",
    "        train_loop.set_description(f'Epoch {epoch + 1} Training')\n",
    "        train_loop.set_postfix({'Accuracy': 100 * training_acc, 'Loss': training_loss})\n",
    "    \n",
    "    # save evaluation metrics\n",
    "    train_acc.append(training_acc)\n",
    "    train_loss.append(training_loss)\n",
    "\n",
    "    # initialize variables to track running metrics\n",
    "    validation_loss = 0.0\n",
    "    validation_acc = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # perform validation step\n",
    "    valid_loop = tqdm(test_loader)\n",
    "    for batch in valid_loop:\n",
    "        # update number of batches\n",
    "        num_batches += 1\n",
    "\n",
    "        # get inputs and labels\n",
    "        inputs, labels = batch[0].to(gpu), batch[1].to(gpu)\n",
    "\n",
    "        # forward pass\n",
    "        with torch.no_grad():\n",
    "            # compute model outputs\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # compute validation loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # save validation loss\n",
    "            validation_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            # save validation accuracy\n",
    "            validation_acc += np.mean(torch.argmax(outputs, dim=1).cpu().numpy() == labels.cpu().numpy()) / len(test_loader)\n",
    "\n",
    "        # format progress bar\n",
    "        valid_loop.set_description(f'Epoch {epoch + 1} Validation')\n",
    "        valid_loop.set_postfix({'Accuracy': 100 * validation_accuracy, 'Loss': validation_loss})\n",
    "    \n",
    "    # save evaluation metrics\n",
    "    valid_acc.append(validation_acc)\n",
    "    valid_loss.append(validation_loss)\n",
    "\n",
    "    # print the average loss for the epoch\n",
    "    # print(f\"Epoch {epoch + 1} - Validation Loss: {np.round(validation_loss / num_batches, 7)} | Validation Accuracy: {np.round(validation_acc / num_batches * 100, 2)}%\")\n",
    "\n",
    "    # save model state\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()},\n",
    "                './ModelStates/income_mlp_' + str(epoch) + '.pkl')\n",
    "\n",
    "    # check for early stopping\n",
    "    if EarlyStop.early_stop(validation_loss):\n",
    "        print(f'Stopping early after {epoch + 1} epochs...')\n",
    "        EPOCHS = epoch + 1\n",
    "        break\n",
    "\n",
    "# calculate training time\n",
    "end_time = time.time()\n",
    "print(f'Model Trained In {np.round(end_time - start_time, 2)} Seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare results for visualization\n",
    "epochs = range(1, EPOCHS)\n",
    "train_acc = [x * 100 for x in train_acc]\n",
    "valid_acc = [x * 100 for x in valid_acc]\n",
    "\n",
    "# initialize plot field\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "fig.suptitle('Model Training Analysis')\n",
    "\n",
    "# plot accuracy results\n",
    "ax1.plot(epochs, train_acc, 'bo', label = 'Training Accuracy')\n",
    "ax1.plot(epochs, valid_acc, 'b', label = 'Validation Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "# plot loss results\n",
    "ax2.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "ax2.plot(epochs, valid_loss, 'b', label='Validation loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
