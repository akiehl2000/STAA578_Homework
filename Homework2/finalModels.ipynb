{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Final Models (Loan Prediction)\n",
    "\n",
    "Adam Kiehl  \n",
    "4/23/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akiehl/miniconda3/envs/dsci/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/akiehl/miniconda3/envs/dsci/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import analysis packages\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import models\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as back\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csvs\n",
    "trainDF = pd.read_csv('./loan_train.csv')\n",
    "testDF = pd.read_csv('./loan_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate response/prediction columns\n",
    "trainResp = np.where(trainDF['MIS_Status'] == 'P I F', 1, 0)\n",
    "trainDF.drop('MIS_Status', axis = 1, inplace = True)\n",
    "testIDs = testDF['CustomerId']\n",
    "testDF.drop('CustomerId', axis = 1, inplace = True)\n",
    "\n",
    "# combine data sets for preprocessing\n",
    "trainDF['source'] = 'train'\n",
    "testDF['source'] = 'test'\n",
    "fullDF = pd.concat([trainDF, testDF], axis = 0)\n",
    "\n",
    "# factor categorical predictors\n",
    "fullDF['NAICS'] = fullDF['NAICS'].apply(lambda x: str(x))\n",
    "fullDF['NewExist'] = fullDF['NewExist'].apply(lambda x: str(x))\n",
    "fullDF['UrbanRural'] = fullDF['UrbanRural'].apply(lambda x: str(x))\n",
    "fullDF['RevLineCr'] = np.where(fullDF['RevLineCr'] == 'Y', 'Y', 'N')\n",
    "fullDF['LowDoc'] = np.where(fullDF['LowDoc'] == 'Y', 'Y', 'N')\n",
    "fullDF['New'] = fullDF['New'].apply(lambda x: str(x))\n",
    "fullDF['RealEstate'] = fullDF['RealEstate'].apply(lambda x: str(x))\n",
    "fullDF['Recession'] = fullDF['Recession'].apply(lambda x: str(x))\n",
    "\n",
    "# selected predictors\n",
    "predictors = ['NAICS', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob', 'UrbanRural', 'RevLineCr', 'LowDoc', 'DisbursementGross', 'GrAppv', 'New', 'RealEstate', 'Portion', 'Recession']\n",
    "src = fullDF['source']\n",
    "fullDF = fullDF[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric predictors and encode categorical predictors\n",
    "findNumPredictors = make_column_selector(dtype_exclude = object)\n",
    "findCatPredictors = make_column_selector(dtype_include = object)\n",
    "transform = make_column_transformer((MinMaxScaler(), findNumPredictors),\n",
    "                                    (OneHotEncoder(), findCatPredictors))\n",
    "\n",
    "# get new column names\n",
    "colNames = transform.fit(fullDF).get_feature_names_out()\n",
    "\n",
    "# transform data\n",
    "modelDF = pd.DataFrame(transform.fit_transform(fullDF), columns = colNames)\n",
    "\n",
    "# split data into training, validation, and test sets\n",
    "modelTrain = modelDF.loc[np.where(src == 'train')]\n",
    "modelTest = modelDF.iloc[np.where(src == 'test')]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(modelTrain, trainResp, test_size = 0.2, random_state = 4192023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation F1 score: 0.865'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tuned hyperparameter\n",
    "M = 38\n",
    "\n",
    "# fit random forest model\n",
    "model1 = RandomForestClassifier(max_features = M, n_estimators = 1000, random_state = 4192023)\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# predict on validation set\n",
    "pred1 = model1.predict(X_valid)\n",
    "\n",
    "# validation accuracy\n",
    "display(f\"Validation F1 score: {f1_score(pred1, y_valid).round(3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Validation F1 score: 0.871'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tuned hyperparameters\n",
    "L = 0.1\n",
    "D = 1\n",
    "\n",
    "# fit gradient boosted model\n",
    "model2 = GradientBoostingClassifier(learning_rate = L, max_depth = D, n_estimators = 1000, random_state = 4192023)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# predict on validation set\n",
    "pred2 = model2.predict(X_valid)\n",
    "\n",
    "# validation accuracy\n",
    "display(f\"Validation F1 score: {f1_score(pred2, y_valid).round(3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               23040     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,633\n",
      "Trainable params: 197,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 5: early stopping\n",
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Validation F1 score: 0.809'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(462023)\n",
    "tf.random.set_seed(482023)\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 1, threshold = 0.5)\n",
    "\n",
    "# penalty hyperparameter\n",
    "PENALTY = 0.025\n",
    "\n",
    "# define model architecture\n",
    "model3 = models.Sequential([\n",
    "    Dense(512, activation = 'relu', kernel_regularizer = l2(PENALTY), input_shape = (X_train.shape[1], )),\n",
    "    Dense(256, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(128, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(64, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(32, activation = 'relu', kernel_regularizer = l2(PENALTY)),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model3.compile(optimizer = 'rmsprop',\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# model summary\n",
    "model3.summary()\n",
    "\n",
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# early stopping criteria\n",
    "earlyStop = EarlyStopping(monitor = 'f1_score', mode = 'max', verbose = 1, patience = 3)\n",
    "\n",
    "# train model\n",
    "trained3 = model3.fit(X_train, \n",
    "                      y_train, \n",
    "                      epochs = EPOCHS, \n",
    "                      batch_size = 64, \n",
    "                      callbacks = earlyStop,\n",
    "                      verbose = 0)\n",
    "\n",
    "# predict on validation set\n",
    "pred3 = model3.predict(X_valid)\n",
    "\n",
    "# validation accuracy\n",
    "display(f\"Validation F1 score: {f1_score(pred3.round(), y_valid).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 512)               23040     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,633\n",
      "Trainable params: 197,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 34: early stopping\n",
      "7/7 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Validation F1 score: 0.848'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(462023)\n",
    "tf.random.set_seed(482023)\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 1, threshold = 0.5)\n",
    "\n",
    "# penalty hyperparameter\n",
    "RATE = 0.1\n",
    "\n",
    "# define model architecture\n",
    "model4 = models.Sequential([\n",
    "    Dense(512, activation = 'relu', input_shape = (X_train.shape[1], )),\n",
    "    Dropout(RATE),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model4.compile(optimizer = 'rmsprop',\n",
    "               loss = 'binary_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# model summary\n",
    "model4.summary()\n",
    "\n",
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# early stopping criteria\n",
    "earlyStop = EarlyStopping(monitor = 'f1_score', mode = 'max', verbose = 1, patience = 3)\n",
    "\n",
    "# train model\n",
    "trained4 = model4.fit(X_train, \n",
    "                      y_train, \n",
    "                      epochs = EPOCHS, \n",
    "                      batch_size = 64, \n",
    "                      callbacks = earlyStop,\n",
    "                      verbose = 0)\n",
    "\n",
    "# predict on validation set\n",
    "pred4 = model4.predict(X_valid)\n",
    "\n",
    "# validation accuracy\n",
    "display(f\"Validation F1 score: {f1_score(pred4.round(), y_valid).round(3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned hyperparameters\n",
    "L = 0.1\n",
    "D = 1\n",
    "\n",
    "# fit gradient boosted model\n",
    "gbFit = GradientBoostingClassifier(learning_rate = L, max_depth = D, n_estimators = 1000, random_state = 4192023)\n",
    "gbFit.fit(modelTrain, trainResp)\n",
    "\n",
    "# predict on test set\n",
    "gbPred = gbFit.predict(modelTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission data frame\n",
    "submission = pd.DataFrame({'CustomerId': testIDs, 'Approve': gbPred})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_76 (Dense)            (None, 512)               23040     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 197,633\n",
      "Trainable params: 197,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 21: early stopping\n",
      "32/32 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "np.random.seed(462023)\n",
    "tf.random.set_seed(482023)\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 1, threshold = 0.5)\n",
    "\n",
    "# penalty hyperparameter\n",
    "RATE = 0.1\n",
    "\n",
    "# define model architecture\n",
    "nnFit = models.Sequential([\n",
    "    Dense(512, activation = 'relu', input_shape = (modelTrain.shape[1], )),\n",
    "    Dropout(RATE),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "# compile model\n",
    "nnFit.compile(optimizer = 'rmsprop',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# model summary\n",
    "nnFit.summary()\n",
    "\n",
    "# number of epochs\n",
    "EPOCHS = 50\n",
    "\n",
    "# early stopping criteria\n",
    "earlyStop = EarlyStopping(monitor = 'f1_score', mode = 'max', verbose = 1, patience = 3)\n",
    "\n",
    "# train model\n",
    "nnFit.fit(modelTrain, \n",
    "          trainResp, \n",
    "          epochs = EPOCHS, \n",
    "          batch_size = 64, \n",
    "          callbacks = earlyStop,\n",
    "          verbose = 0)\n",
    "\n",
    "# predict on test set\n",
    "nnPred = nnFit.predict(modelTest).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission data frame\n",
    "submission = pd.DataFrame({'CustomerId': testIDs, 'Approve': nnPred.reshape(len(nnPred), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
