{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Final Models (Loan Prediction)\n",
    "\n",
    "Adam Kiehl  \n",
    "4/23/23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akiehl/miniconda3/envs/dsci/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/akiehl/miniconda3/envs/dsci/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import analysis packages\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import models\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as back\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csvs\n",
    "trainDF = pd.read_csv('./loan_train.csv')\n",
    "testDF = pd.read_csv('./loan_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate response/prediction columns\n",
    "trainResp = np.where(trainDF['MIS_Status'] == 'P I F', 1, 0)\n",
    "trainDF.drop('MIS_Status', axis = 1, inplace = True)\n",
    "testIDs = testDF['CustomerId']\n",
    "testDF.drop('CustomerId', axis = 1, inplace = True)\n",
    "\n",
    "# combine data sets for preprocessing\n",
    "trainDF['source'] = 'train'\n",
    "testDF['source'] = 'test'\n",
    "fullDF = pd.concat([trainDF, testDF], axis = 0)\n",
    "\n",
    "# factor categorical predictors\n",
    "fullDF['NAICS'] = fullDF['NAICS'].apply(lambda x: str(x))\n",
    "fullDF['NewExist'] = fullDF['NewExist'].apply(lambda x: str(x))\n",
    "fullDF['UrbanRural'] = fullDF['UrbanRural'].apply(lambda x: str(x))\n",
    "fullDF['RevLineCr'] = np.where(fullDF['RevLineCr'] == 'Y', 'Y', 'N')\n",
    "fullDF['LowDoc'] = np.where(fullDF['LowDoc'] == 'Y', 'Y', 'N')\n",
    "fullDF['New'] = fullDF['New'].apply(lambda x: str(x))\n",
    "fullDF['RealEstate'] = fullDF['RealEstate'].apply(lambda x: str(x))\n",
    "fullDF['Recession'] = fullDF['Recession'].apply(lambda x: str(x))\n",
    "\n",
    "# selected predictors\n",
    "predictors = ['NAICS', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob', 'UrbanRural', 'RevLineCr', 'LowDoc', 'DisbursementGross', 'GrAppv', 'New', 'RealEstate', 'Portion', 'Recession']\n",
    "src = fullDF['source']\n",
    "fullDF = fullDF[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric predictors and encode categorical predictors\n",
    "findNumPredictors = make_column_selector(dtype_exclude = object)\n",
    "findCatPredictors = make_column_selector(dtype_include = object)\n",
    "transform = make_column_transformer((MinMaxScaler(), findNumPredictors),\n",
    "                                    (OneHotEncoder(), findCatPredictors))\n",
    "\n",
    "# get new column names\n",
    "colNames = transform.fit(fullDF).get_feature_names_out()\n",
    "\n",
    "# transform data\n",
    "modelDF = pd.DataFrame(transform.fit_transform(fullDF), columns = colNames)\n",
    "\n",
    "# split data into training, validation, and test sets\n",
    "modelTrain = modelDF.loc[np.where(src == 'train')]\n",
    "modelTest = modelDF.iloc[np.where(src == 'test')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned hyperparameters\n",
    "L = 0.1\n",
    "D = 1\n",
    "\n",
    "# fit gradient boosted model\n",
    "model1 = GradientBoostingClassifier(learning_rate = L, max_depth = D, n_estimators = 1000, random_state = 4192023)\n",
    "model1.fit(modelTrain, trainResp)\n",
    "\n",
    "# predict on validation set\n",
    "pred1 = model1.predict(modelTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
