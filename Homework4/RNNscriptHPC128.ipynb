{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import analysis packages\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, SimpleRNN, TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csv files\n",
    "trainDF = pd.read_csv('./ibotta_train.csv')\n",
    "testDF = pd.read_csv('./ibotta_test.csv')\n",
    "\n",
    "# combine data sets for preprocessing\n",
    "trainDF['origin'] = 'train'\n",
    "testDF['origin'] = 'test'\n",
    "fullDF = pd.concat([trainDF, testDF])\n",
    "\n",
    "# combine name and brand name fields\n",
    "fullDF['Brand_name'].where(-fullDF['Brand_name'].isna(), '', inplace = True)\n",
    "fullDF['Full_text'] = fullDF['Brand_name'] + ' ' + fullDF['Name']\n",
    "\n",
    "# seed random seed\n",
    "random.seed(542023)\n",
    "\n",
    "# split data\n",
    "trainDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'train'].drop('origin', axis = 1))\n",
    "testDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'test'].drop(['origin', 'Category'], axis = 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train integer index tokenizer\n",
    "intTokenizer = TextVectorization()\n",
    "intTokenizer.adapt(fullDF['Full_text'])\n",
    "\n",
    "# vectorize text data\n",
    "intVecDF = pd.DataFrame(intTokenizer(fullDF['Full_text']))\n",
    "trainDFintVec = intVecDF.loc[0:7999]\n",
    "testDFintVec = intVecDF.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bag of words tokenizer\n",
    "countTokenizer = TextVectorization(output_mode = 'multi_hot')\n",
    "countTokenizer.adapt(fullDF['Full_text'])\n",
    "\n",
    "# vectorize text data\n",
    "countVecDF = pd.DataFrame(countTokenizer(fullDF['Full_text']))\n",
    "trainDFcountVec = countVecDF.loc[0:7999]\n",
    "testDFcountVec = countVecDF.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train truncated bag of words tokenizer\n",
    "countTokenizer1000 = TextVectorization(output_mode = 'multi_hot',\n",
    "                                       vocabulary = countTokenizer.get_vocabulary()[0:1000])\n",
    "\n",
    "# vectorize text data\n",
    "countVec1000DF = pd.DataFrame(countTokenizer1000(fullDF['Full_text']))\n",
    "trainDFcountVec1000 = countVec1000DF.loc[0:7999]\n",
    "testDFcountVec1000 = countVec1000DF.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tfidf tokenizer\n",
    "tfidfTokenizer = TextVectorization(output_mode = 'tf_idf')\n",
    "tfidfTokenizer.adapt(fullDF['Full_text'])\n",
    "\n",
    "# vectorize text data\n",
    "tfidfVecDF = pd.DataFrame(tfidfTokenizer(fullDF['Full_text']))\n",
    "trainDFtfidfVec = tfidfVecDF.loc[0:7999]\n",
    "testDFtfidfVec = tfidfVecDF.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tfidf tokenizer\n",
    "tfidfTokenizer1000 = TextVectorization(output_mode = 'tf_idf', \n",
    "                                       vocabulary = tfidfTokenizer.get_vocabulary()[0:1000],\n",
    "                                       idf_weights = tfidfTokenizer.get_weights()[0][0:1000])\n",
    "\n",
    "# vectorize text data\n",
    "tfidfVec1000DF = pd.DataFrame(tfidfTokenizer1000(fullDF['Full_text']))\n",
    "trainDFtfidfVec1000 = tfidfVec1000DF.loc[0:7999]\n",
    "testDFtfidfVec1000 = tfidfVec1000DF.loc[8000:9999]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation function\n",
    "def EvaluateModel(model, X_train):\n",
    "    # set random seeds\n",
    "    np.random.seed(542023)\n",
    "    tf.random.set_seed(542023)\n",
    "\n",
    "    # print model summary\n",
    "    try:\n",
    "        model.summary()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # define F1 metric\n",
    "    f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy', f1_score_metric])\n",
    "    \n",
    "    # define early stopping criterion\n",
    "    early = EarlyStopping(monitor = 'val_f1_score', mode = 'max', patience = 3)\n",
    "\n",
    "    # train deep learning model\n",
    "    trained = model.fit(X_train,\n",
    "                        to_categorical(trainDF['Cat_code']),\n",
    "                        epochs = 100,\n",
    "                        batch_size = 128,\n",
    "                        callbacks = early,\n",
    "                        validation_split = 0.15,\n",
    "                        verbose = 1)\n",
    "    \n",
    "    # prepare model evaluation\n",
    "    acc = trained.history['accuracy']\n",
    "    val_acc = trained.history['val_accuracy']\n",
    "    loss = trained.history['loss']\n",
    "    val_loss = trained.history['val_loss']\n",
    "    f1_score = trained.history['f1_score']\n",
    "    val_f1_score = trained.history['val_f1_score']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # final validation accuracy\n",
    "    display(f\"Internal validation accuracy: {round(val_acc[-1] * 100, 2)}%\")\n",
    "    display(f'Internal validation F1 score: {round(val_f1_score[-1], 4)}')\n",
    "\n",
    "    # plot training accuracy\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize = (15, 5))\n",
    "    ax1.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "    ax1.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "    ax1.set(xlabel = 'Epochs', ylabel = 'Accuracy')\n",
    "    ax1.legend()\n",
    "    ax2.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "    ax2.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "    ax2.set(xlabel = 'Epochs', ylabel = 'Loss')\n",
    "    ax2.legend()\n",
    "    ax3.plot(epochs, f1_score, 'bo', label = 'Training F1')\n",
    "    ax3.plot(epochs, val_f1_score, 'b', label = 'Validation F1')\n",
    "    ax3.set(xlabel = 'Epochs', ylabel = 'F1 Score')\n",
    "    ax3.legend()\n",
    "    fig.suptitle('Evaluation Metrics')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 8, input_shape = (4880, )),\n",
    "    SimpleRNN(16),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFcountVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 8, input_shape = (4880, )),\n",
    "    SimpleRNN(16),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtfidfVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 8, input_shape = (4880, )),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFcountVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 8, input_shape = (4880, )),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtfidfVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 16, input_shape = (4880, )),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFcountVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 16, input_shape = (4880, )),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtfidfVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 16, input_shape = (4880, )),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFcountVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4880, 16, input_shape = (4880, )),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtfidfVec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
