{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import analysis packages\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, SimpleRNN, TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csv files\n",
    "trainDF = pd.read_csv('./ibotta_train.csv')\n",
    "testDF = pd.read_csv('./ibotta_test.csv')\n",
    "\n",
    "# combine data sets for preprocessing\n",
    "trainDF['origin'] = 'train'\n",
    "testDF['origin'] = 'test'\n",
    "fullDF = pd.concat([trainDF, testDF])\n",
    "\n",
    "# text cleaning\n",
    "fullDF['Brand_name'].where(-fullDF['Brand_name'].isna(), '', inplace = True)\n",
    "fullDF['Brand_name'] = fullDF['Brand_name'].apply(lambda x: x.lower().replace(\"'\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"-\", \"\").replace(\".\", \"\"))\n",
    "fullDF['Name'] = fullDF['Name'].apply(lambda x: x.lower().replace(\"'\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"-\", \"\").replace(\".\", \"\"))\n",
    "\n",
    "# combine brand and name fields\n",
    "fullDF['brandAlready'] = fullDF.apply(lambda x: x['Name'].find(x['Brand_name']), axis = 1)\n",
    "fullDF.loc[fullDF.brandAlready == -1, 'Name'] = fullDF.loc[fullDF.brandAlready == -1, 'Brand_name'] + \\\n",
    "    ' ' + fullDF.loc[fullDF.brandAlready == -1, 'Name']\n",
    "fullDF.drop('brandAlready', axis = 1, inplace = True)\n",
    "\n",
    "# seed random seed\n",
    "random.seed(542023)\n",
    "\n",
    "# split data\n",
    "trainDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'train'].drop('origin', axis = 1))\n",
    "validIdx = random.sample(list(trainDF['Id'] - 1), 1000)\n",
    "validDF = trainDF.loc[validIdx]\n",
    "trainDF = trainDF.loc[trainDF['Id'].apply(lambda x: x not in validIdx)]\n",
    "testDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'test'].drop(['origin', 'Category'], axis = 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total number of unique words\n",
    "unique_words = np.unique(np.array(' '.join(np.array(fullDF['Name'])).split(' ')))\n",
    "max_length = len(unique_words)\n",
    "\n",
    "# initialize empty dataframe\n",
    "wordBag = pd.DataFrame(np.zeros((len(fullDF), max_length)), \n",
    "                       columns = unique_words)\n",
    "\n",
    "# loop through product names\n",
    "for i, productName in enumerate(fullDF['Name'].apply(lambda x: x.split(' '))):\n",
    "    # loop through words in name\n",
    "    for word in productName:\n",
    "        # identify word presence\n",
    "        wordBag.loc[i, word] = 1\n",
    "\n",
    "# split word bag\n",
    "trainDFwordBag = wordBag.loc[0:7999]\n",
    "validDFwordBag = trainDFwordBag.loc[validIdx]\n",
    "trainDFwordBag = trainDFwordBag.loc[pd.Series(trainDFwordBag.index).apply(lambda x: x not in validIdx)]\n",
    "testDFwordBag = wordBag.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag data with iterable object\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(fullDF['Name'].apply(lambda x: x.split(' ')))]\n",
    "\n",
    "# doc2vec vectorization function\n",
    "def doc2vecGen(size):\n",
    "    # train doc2vec tokenizer\n",
    "    tokenizer = Doc2Vec(tagged_data, vector_size = size, min_count = 1, epochs = 100)\n",
    "    tokenizer.build_vocab(list(tagged_data))\n",
    "    tokenizer.train(list(tagged_data), \n",
    "                    total_examples = size, \n",
    "                    epochs = tokenizer.epochs)\n",
    "    \n",
    "    # vectorize text data\n",
    "    doc2vecDF = fullDF['Name'].apply(lambda x: tokenizer.infer_vector(x.split(' ')))\n",
    "    doc2vecDF = pd.DataFrame(np.array(doc2vecDF))[0].apply(pd.Series)\n",
    "\n",
    "    # split vectorized data\n",
    "    trainDFdoc2vec = doc2vecDF.loc[0:7999]\n",
    "    validDFdoc2vec = doc2vecDF.loc[validIdx]\n",
    "    trainDFdoc2vec = trainDFdoc2vec.loc[pd.Series(trainDFdoc2vec.index).apply(lambda x: x not in validIdx)]\n",
    "    testDFdoc2vec = doc2vecDF.loc[8000:9999]\n",
    "\n",
    "    return(trainDFdoc2vec, validDFdoc2vec, testDFdoc2vec)\n",
    "\n",
    "# generate vectorized data\n",
    "# trainDFdoc2vecMAX, validDFdoc2vecMAX, testDFdoc2vecMAX = doc2vecGen(max_length)\n",
    "# trainDFdoc2vec1000, validDFdoc2vec1000, testDFdoc2vec1000 = doc2vecGen(1000)\n",
    "# trainDFdoc2vec500, validDFdoc2vec500, testDFdoc2vec500 = doc2vecGen(500)\n",
    "# trainDFdoc2vec100, validDFdoc2vec100, testDFdoc2vec100 = doc2vecGen(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-05 12:04:08.952118: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# keras tokenizer function\n",
    "def textVecGen(size):\n",
    "    # train keras tokenizer\n",
    "    tokenizer = TextVectorization(max_tokens = size,\n",
    "                                  output_sequence_length = size)\n",
    "    tokenizer.adapt(fullDF['Name'])\n",
    "\n",
    "    # vectorize data\n",
    "    textVecDF = pd.DataFrame(tokenizer(fullDF['Name']))\n",
    "    \n",
    "    # split vectorized data\n",
    "    trainDFtextVec = textVecDF.loc[0:7999]\n",
    "    validDFtextVec = trainDFtextVec.loc[validIdx]\n",
    "    trainDFtextVec = trainDFtextVec.loc[pd.Series(trainDFtextVec.index).apply(lambda x: x not in validIdx)]\n",
    "    testDFtextVec = textVecDF.loc[8000:9999]\n",
    "\n",
    "    return(trainDFtextVec, validDFtextVec, testDFtextVec)\n",
    "\n",
    "# generate vectorized data\n",
    "trainDFtextVecMAX, validDFtextVecMAX, testDFtextVecMAX = textVecGen(max_length)\n",
    "trainDFtextVec1000, validDFtextVec1000, testDFtextVec1000 = textVecGen(1000)\n",
    "trainDFtextVec500, validDFtextVec500, testDFtextVec500 = textVecGen(500)\n",
    "trainDFtextVec100, validDFtextVec100, testDFtextVec100 = textVecGen(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation function\n",
    "def EvaluateModel(model, X_train):\n",
    "    # set random seeds\n",
    "    np.random.seed(542023)\n",
    "    tf.random.set_seed(542023)\n",
    "\n",
    "    # print model summary\n",
    "    try:\n",
    "        model.summary()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer = 'rmsprop',\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    # define early stopping criterion\n",
    "    early = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 3)\n",
    "\n",
    "    # train deep learning model\n",
    "    trained = model.fit(X_train,\n",
    "                        to_categorical(trainDF['Cat_code']),\n",
    "                        epochs = 100,\n",
    "                        batch_size = 32,\n",
    "                        callbacks = early,\n",
    "                        validation_split = 0.15,\n",
    "                        verbose = 1)\n",
    "    \n",
    "    # prepare model evaluation\n",
    "    acc = trained.history['accuracy']\n",
    "    val_acc = trained.history['val_accuracy']\n",
    "    loss = trained.history['loss']\n",
    "    val_loss = trained.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # final validation accuracy\n",
    "    display(f\"Internal validation accuracy: {round(val_acc[-1] * 100, 2)}%\")\n",
    "\n",
    "    # plot training accuracy\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (15, 5))\n",
    "    ax1.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "    ax1.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "    ax1.set(xlabel = 'Epochs', ylabel = 'Accuracy')\n",
    "    ax1.legend()\n",
    "    ax2.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "    ax2.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "    ax2.set(xlabel = 'Epochs', ylabel = 'Loss')\n",
    "    ax2.legend()\n",
    "    fig.suptitle('Evaluation Metrics')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(100, 128),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVec100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(100, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVec100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(500, 128),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVec500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(500, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVec500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(1000, 128),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVec1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(1000, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVec1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4977, 128),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVecMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4977, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "EvaluateModel(model, trainDFtextVecMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(100, 128),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vec100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(100, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vec100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(500, 128),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vec500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(500, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vec500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(1000, 128, input_shape = (1000, )),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vec1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(1000, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vec1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4977, 128, input_shape = (4977, )),\n",
    "    SimpleRNN(32),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vecMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "model = Sequential([\n",
    "    Embedding(4977, 8),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32, return_sequences = True),\n",
    "    SimpleRNN(32),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# evaluate model\n",
    "# EvaluateModel(model, trainDFdoc2vecMAX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
