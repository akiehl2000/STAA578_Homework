{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 Final Models (Text Classification)\n",
    "\n",
    "Adam Kiehl  \n",
    "5/11/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akiehl/miniconda3/envs/dsci/lib/python3.8/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/Users/akiehl/miniconda3/envs/dsci/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import analysis packages\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, SimpleRNN, TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csv files\n",
    "trainDF = pd.read_csv('./ibotta_train.csv')\n",
    "testDF = pd.read_csv('./ibotta_test.csv')\n",
    "\n",
    "# combine data sets for preprocessing\n",
    "trainDF['origin'] = 'train'\n",
    "testDF['origin'] = 'test'\n",
    "fullDF = pd.concat([trainDF, testDF])\n",
    "\n",
    "# combine name and brand name fields\n",
    "fullDF['Brand_name'].where(-fullDF['Brand_name'].isna(), '', inplace = True)\n",
    "fullDF['Full_text'] = fullDF['Brand_name'] + ' ' + fullDF['Name']\n",
    "\n",
    "# seed random seed\n",
    "random.seed(542023)\n",
    "\n",
    "# split data\n",
    "trainDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'train'].drop('origin', axis = 1))\n",
    "testDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'test'].drop(['origin', 'Category'], axis = 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 13:25:43.408047: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# train integer index tokenizer\n",
    "intTokenizer = TextVectorization()\n",
    "intTokenizer.adapt(fullDF['Full_text'])\n",
    "\n",
    "# vectorize text data\n",
    "intVecDF = pd.DataFrame(intTokenizer(fullDF['Full_text']))\n",
    "trainDFintVec = intVecDF.loc[0:7999]\n",
    "testDFintVec = intVecDF.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bag of words tokenizer\n",
    "countTokenizer = TextVectorization(output_mode = 'multi_hot')\n",
    "countTokenizer.adapt(fullDF['Full_text'])\n",
    "\n",
    "# vectorize text data\n",
    "countVecDF = pd.DataFrame(countTokenizer(fullDF['Full_text']))\n",
    "trainDFcountVec = countVecDF.loc[0:7999]\n",
    "testDFcountVec = countVecDF.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tfidf tokenizer\n",
    "tfidfTokenizer = TextVectorization(output_mode = 'tf_idf')\n",
    "tfidfTokenizer.adapt(fullDF['Full_text'])\n",
    "\n",
    "# vectorize text data\n",
    "tfidfVecDF = pd.DataFrame(tfidfTokenizer(fullDF['Full_text']))\n",
    "trainDFtfidfVec = tfidfVecDF.loc[0:7999]\n",
    "testDFtfidfVec = tfidfVecDF.loc[8000:9999]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 2s 22ms/step - loss: 0.6611 - accuracy: 0.7745 - f1_score: 0.7746\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.1063 - accuracy: 0.9709 - f1_score: 0.9709\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0474 - accuracy: 0.9847 - f1_score: 0.9847\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9895 - f1_score: 0.9895\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9936 - f1_score: 0.9936\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0134 - accuracy: 0.9945 - f1_score: 0.9945\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9959 - f1_score: 0.9959\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0083 - accuracy: 0.9961 - f1_score: 0.9961\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0050 - accuracy: 0.9981 - f1_score: 0.9981\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0042 - accuracy: 0.9981 - f1_score: 0.9981\n",
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model architecture\n",
    "model1 = Sequential([\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model1.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# train deep learning model\n",
    "trained1 = model1.fit(trainDFcountVec,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 10,\n",
    "                      batch_size = 128,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred1 = model1.predict(testDFcountVec)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred1, axis = 1).reshape(len(pred1), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 4s 46ms/step - loss: 2.5798 - accuracy: 0.6991 - f1_score: 0.6902\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.7858 - accuracy: 0.9496 - f1_score: 0.9496\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.5069 - accuracy: 0.9599 - f1_score: 0.9598\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.3944 - accuracy: 0.9615 - f1_score: 0.9615\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.3275 - accuracy: 0.9645 - f1_score: 0.9645\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 3s 46ms/step - loss: 0.2782 - accuracy: 0.9705 - f1_score: 0.9705\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 0.2450 - accuracy: 0.9710 - f1_score: 0.9710\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.2180 - accuracy: 0.9761 - f1_score: 0.9761\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.2087 - accuracy: 0.9737 - f1_score: 0.9737\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 3s 43ms/step - loss: 0.1890 - accuracy: 0.9772 - f1_score: 0.9772\n",
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model hyperparameters\n",
    "PENALTY = 0.001\n",
    "RATE = 0.2\n",
    "\n",
    "# define model architecture\n",
    "model2 = Sequential([\n",
    "    Dense(2048, kernel_regularizer = l2(PENALTY), activation = 'relu'),\n",
    "    Dense(1024, kernel_regularizer = l2(PENALTY), activation = 'relu'),\n",
    "    Dropout(RATE),\n",
    "    Dense(512, kernel_regularizer = l2(PENALTY), activation = 'relu'),\n",
    "    Dense(256, kernel_regularizer = l2(PENALTY), activation = 'relu'),\n",
    "    Dense(128, kernel_regularizer = l2(PENALTY), activation = 'relu'),\n",
    "    Dense(64, kernel_regularizer = l2(PENALTY), activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model2.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# train deep learning model\n",
    "trained2 = model2.fit(trainDFtfidfVec,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 10,\n",
    "                      batch_size = 128,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred2 = model2.predict(testDFtfidfVec)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred2, axis = 1).reshape(len(pred2), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "250/250 [==============================] - 200s 799ms/step - loss: 1.5559 - accuracy: 0.6158 - f1_score: 0.6093\n",
      "Epoch 2/12\n",
      "250/250 [==============================] - 175s 701ms/step - loss: 0.1838 - accuracy: 0.9436 - f1_score: 0.9436\n",
      "Epoch 3/12\n",
      "250/250 [==============================] - 151s 605ms/step - loss: 0.1256 - accuracy: 0.9632 - f1_score: 0.9632\n",
      "Epoch 4/12\n",
      "250/250 [==============================] - 142s 570ms/step - loss: 0.0933 - accuracy: 0.9704 - f1_score: 0.9704\n",
      "Epoch 5/12\n",
      "250/250 [==============================] - 138s 551ms/step - loss: 0.0753 - accuracy: 0.9797 - f1_score: 0.9798\n",
      "Epoch 6/12\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.0667 - accuracy: 0.9804 - f1_score: 0.9804\n",
      "Epoch 7/12\n",
      "250/250 [==============================] - 128s 510ms/step - loss: 0.0616 - accuracy: 0.9846 - f1_score: 0.9846\n",
      "Epoch 8/12\n",
      "250/250 [==============================] - 125s 500ms/step - loss: 0.0537 - accuracy: 0.9858 - f1_score: 0.9857\n",
      "Epoch 9/12\n",
      "250/250 [==============================] - 119s 474ms/step - loss: 0.0396 - accuracy: 0.9884 - f1_score: 0.9884\n",
      "Epoch 10/12\n",
      "250/250 [==============================] - 108s 433ms/step - loss: 0.0397 - accuracy: 0.9893 - f1_score: 0.9893\n",
      "Epoch 11/12\n",
      "250/250 [==============================] - 111s 444ms/step - loss: 0.0333 - accuracy: 0.9908 - f1_score: 0.9907\n",
      "Epoch 12/12\n",
      "250/250 [==============================] - 105s 418ms/step - loss: 0.0319 - accuracy: 0.9915 - f1_score: 0.9915\n",
      "63/63 [==============================] - 2s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model architecture\n",
    "model3 = Sequential([\n",
    "    Embedding(4880, 64, input_shape = (4880, )),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model3.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# train deep learning model\n",
    "trained3 = model3.fit(trainDFcountVec,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 12,\n",
    "                      batch_size = 32,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred3 = model3.predict(testDFcountVec)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred3, axis = 1).reshape(len(pred3), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "250/250 [==============================] - 210s 840ms/step - loss: 1.6101 - accuracy: 0.5831 - f1_score: 0.5744\n",
      "Epoch 2/12\n",
      "250/250 [==============================] - 58s 230ms/step - loss: 1.5591 - accuracy: 0.3799 - f1_score: 0.3467\n",
      "Epoch 3/12\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 1.7687 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 4/12\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 1.7684 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 5/12\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 1.7686 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 6/12\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 1.7686 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 7/12\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 1.7684 - accuracy: 0.2936 - f1_score: 0.1473\n",
      "Epoch 8/12\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 1.7686 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 9/12\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 1.7684 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 10/12\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 1.7684 - accuracy: 0.2934 - f1_score: 0.1386\n",
      "Epoch 11/12\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 1.7685 - accuracy: 0.2940 - f1_score: 0.1336\n",
      "Epoch 12/12\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 1.7682 - accuracy: 0.2939 - f1_score: 0.1353\n",
      "63/63 [==============================] - 2s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model architecture\n",
    "model4 = Sequential([\n",
    "    Embedding(4880, 64, input_shape = (4880, )),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model4.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# train deep learning model\n",
    "trained4 = model4.fit(trainDFtfidfVec,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 12,\n",
    "                      batch_size = 32,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred4 = model4.predict(testDFtfidfVec)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred4, axis = 1).reshape(len(pred4), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 2s 21ms/step - loss: 0.5937 - accuracy: 0.8036 - f1_score: 0.8035\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0741 - accuracy: 0.9793 - f1_score: 0.9792\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.0327 - accuracy: 0.9902 - f1_score: 0.9902\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0186 - accuracy: 0.9930 - f1_score: 0.9930\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0135 - accuracy: 0.9952 - f1_score: 0.9952\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0091 - accuracy: 0.9974 - f1_score: 0.9974\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0064 - accuracy: 0.9974 - f1_score: 0.9974\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0040 - accuracy: 0.9985 - f1_score: 0.9985\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0038 - accuracy: 0.9986 - f1_score: 0.9986\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.9991 - f1_score: 0.9991\n",
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model architecture\n",
    "model5 = Sequential([\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model5.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "\n",
    "# train deep learning model\n",
    "trained5 = model5.fit(trainDFtfidfVec,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 10,\n",
    "                      batch_size = 128,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred5 = model5.predict(testDFtfidfVec)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred5, axis = 1).reshape(len(pred5), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission5.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
