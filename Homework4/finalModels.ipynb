{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 Final Models (Text Classification)\n",
    "\n",
    "Adam Kiehl  \n",
    "5/7/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import analysis packages\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, SimpleRNN, TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from .csv files\n",
    "trainDF = pd.read_csv('./ibotta_train.csv')\n",
    "testDF = pd.read_csv('./ibotta_test.csv')\n",
    "\n",
    "# combine data sets for preprocessing\n",
    "trainDF['origin'] = 'train'\n",
    "testDF['origin'] = 'test'\n",
    "fullDF = pd.concat([trainDF, testDF])\n",
    "\n",
    "# text cleaning\n",
    "fullDF['Brand_name'].where(-fullDF['Brand_name'].isna(), '', inplace = True)\n",
    "fullDF['Brand_name'] = fullDF['Brand_name'].apply(lambda x: x.lower().replace(\"'\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"-\", \"\").replace(\".\", \"\"))\n",
    "fullDF['Name'] = fullDF['Name'].apply(lambda x: x.lower().replace(\"'\", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"-\", \"\").replace(\".\", \"\"))\n",
    "\n",
    "# combine brand and name fields\n",
    "fullDF['brandAlready'] = fullDF.apply(lambda x: x['Name'].find(x['Brand_name']), axis = 1)\n",
    "fullDF.loc[fullDF.brandAlready == -1, 'Name'] = fullDF.loc[fullDF.brandAlready == -1, 'Brand_name'] + \\\n",
    "    ' ' + fullDF.loc[fullDF.brandAlready == -1, 'Name']\n",
    "fullDF.drop('brandAlready', axis = 1, inplace = True)\n",
    "\n",
    "# split data\n",
    "trainDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'train'].drop('origin', axis = 1))\n",
    "testDF = pd.DataFrame(fullDF.loc[fullDF['origin'] == 'test'].drop(['origin', 'Category'], axis = 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find total number of unique words\n",
    "unique_words = np.unique(np.array(' '.join(np.array(fullDF['Name'])).split(' ')))\n",
    "max_length = len(unique_words)\n",
    "\n",
    "# initialize empty dataframe\n",
    "wordBag = pd.DataFrame(np.zeros((len(fullDF), max_length)), \n",
    "                       columns = unique_words)\n",
    "\n",
    "# loop through product names\n",
    "for i, productName in enumerate(fullDF['Name'].apply(lambda x: x.split(' '))):\n",
    "    # loop through words in name\n",
    "    for word in productName:\n",
    "        # identify word presence\n",
    "        wordBag.loc[i, word] = 1\n",
    "\n",
    "# split word bag\n",
    "trainDFwordBag = wordBag.loc[0:7999]\n",
    "testDFwordBag = wordBag.loc[8000:9999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras tokenizer function\n",
    "def textVecGen(size):\n",
    "    # train keras tokenizer\n",
    "    tokenizer = TextVectorization(max_tokens = size, \n",
    "                                  output_sequence_length = size)\n",
    "    tokenizer.adapt(fullDF['Name'])\n",
    "\n",
    "    # vectorize data\n",
    "    textVecDF = pd.DataFrame(tokenizer(fullDF['Name']))\n",
    "    \n",
    "    # split vectorized data\n",
    "    trainDFtextVec = textVecDF.loc[0:7999]\n",
    "    testDFtextVec = textVecDF.loc[8000:9999]\n",
    "\n",
    "    return(trainDFtextVec, testDFtextVec)\n",
    "\n",
    "# generate vectorized data\n",
    "trainDFtextVec1000, testDFtextVec1000 = textVecGen(1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 23ms/step - loss: 0.6617 - accuracy: 0.7756 - f1_score: 0.7751\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.1072 - accuracy: 0.9715 - f1_score: 0.9715\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0493 - accuracy: 0.9856 - f1_score: 0.9856\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9904 - f1_score: 0.9904\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0172 - accuracy: 0.9946 - f1_score: 0.9946\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0131 - accuracy: 0.9946 - f1_score: 0.9946\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9964 - f1_score: 0.9964\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0076 - accuracy: 0.9966 - f1_score: 0.9966\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0055 - accuracy: 0.9983 - f1_score: 0.9982\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0040 - accuracy: 0.9985 - f1_score: 0.9985\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0036 - accuracy: 0.9990 - f1_score: 0.9990\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0024 - accuracy: 0.9990 - f1_score: 0.9990\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.9991 - f1_score: 0.9991\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 0.9991 - f1_score: 0.9991\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0021 - accuracy: 0.9991 - f1_score: 0.9991\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0015 - accuracy: 0.9992 - f1_score: 0.9992\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0020 - accuracy: 0.9991 - f1_score: 0.9991\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.0015 - accuracy: 0.9994 - f1_score: 0.9994\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.0013 - accuracy: 0.9994 - f1_score: 0.9994\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0012 - accuracy: 0.9994 - f1_score: 0.9994\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0012 - accuracy: 0.9995 - f1_score: 0.9995\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0012 - accuracy: 0.9994 - f1_score: 0.9994\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0013 - accuracy: 0.9990 - f1_score: 0.9990\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 9.1478e-04 - accuracy: 0.9995 - f1_score: 0.9995\n",
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model architecture\n",
    "model1 = Sequential([\n",
    "    Dense(512, activation = 'relu'),\n",
    "    Dense(256, activation = 'relu'),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model1.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "    \n",
    "# define early stopping criterion\n",
    "early = EarlyStopping(monitor = 'f1_score', mode = 'max', patience = 3)\n",
    "\n",
    "# train deep learning model\n",
    "trained1 = model1.fit(trainDFwordBag,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 100,\n",
    "                      batch_size = 128,\n",
    "                      callbacks = early,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred1 = model1.predict(testDFwordBag)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred1, axis = 1).reshape(len(pred1), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1000, 128)         128000    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 128000)            0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               16384128  \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,520,839\n",
      "Trainable params: 16,520,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 1.3339 - accuracy: 0.5515 - f1_score: 0.5149\n",
      "Epoch 2/100\n",
      "211/250 [========================>.....] - ETA: 8s - loss: 0.3990 - accuracy: 0.8796 - f1_score: 0.4044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x3ee686220>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x137dc5a00>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x137f12e00>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x137dc5a00>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/250 [===========================>..] - ETA: 3s - loss: 0.3856 - accuracy: 0.8842 - f1_score: 0.8841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x3d74d2e90>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x137dc5a00>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x137f12e00>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x137dc5a00>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 53s 213ms/step - loss: 0.3799 - accuracy: 0.8859 - f1_score: 0.8859\n",
      "Epoch 3/100\n",
      " 13/250 [>.............................] - ETA: 42s - loss: 0.2234 - accuracy: 0.9471 - f1_score: 0.9473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x3f4cde460>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x137dc5a00>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x137f12e00>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x137dc5a00>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x3f2c2dd40>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x137dc5a00>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x137f12e00>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x137dc5a00>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 48s 194ms/step - loss: 0.2284 - accuracy: 0.9321 - f1_score: 0.9322\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 46s 183ms/step - loss: 0.1839 - accuracy: 0.9446 - f1_score: 0.9447\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 45s 182ms/step - loss: 0.1534 - accuracy: 0.9499 - f1_score: 0.9499\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 41s 166ms/step - loss: 0.1343 - accuracy: 0.9569 - f1_score: 0.9569\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 41s 166ms/step - loss: 0.1209 - accuracy: 0.9645 - f1_score: 0.9645\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 40s 162ms/step - loss: 0.1128 - accuracy: 0.9653 - f1_score: 0.9653\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 41s 163ms/step - loss: 0.1001 - accuracy: 0.9704 - f1_score: 0.9704\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 37s 146ms/step - loss: 0.0961 - accuracy: 0.9705 - f1_score: 0.9705\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 36s 143ms/step - loss: 0.0894 - accuracy: 0.9741 - f1_score: 0.9741\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 34s 137ms/step - loss: 0.0806 - accuracy: 0.9744 - f1_score: 0.9744\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 34s 134ms/step - loss: 0.0780 - accuracy: 0.9741 - f1_score: 0.9741\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.0721 - accuracy: 0.9765 - f1_score: 0.9765\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.0651 - accuracy: 0.9803 - f1_score: 0.9803\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.0607 - accuracy: 0.9805 - f1_score: 0.9805\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 31s 126ms/step - loss: 0.0605 - accuracy: 0.9815 - f1_score: 0.9815\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0552 - accuracy: 0.9829 - f1_score: 0.9829\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0553 - accuracy: 0.9827 - f1_score: 0.9828\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.0560 - accuracy: 0.9840 - f1_score: 0.9840\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.0506 - accuracy: 0.9846 - f1_score: 0.9846\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.0490 - accuracy: 0.9850 - f1_score: 0.9850\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 28s 110ms/step - loss: 0.0501 - accuracy: 0.9856 - f1_score: 0.9856\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.0460 - accuracy: 0.9876 - f1_score: 0.9876\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.0419 - accuracy: 0.9874 - f1_score: 0.9874\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.0419 - accuracy: 0.9865 - f1_score: 0.9865\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 27s 107ms/step - loss: 0.0389 - accuracy: 0.9876 - f1_score: 0.9876\n",
      "63/63 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# set random seeds\n",
    "np.random.seed(542023)\n",
    "tf.random.set_seed(542023)\n",
    "\n",
    "# define model architecture\n",
    "model2 = Sequential([\n",
    "    Embedding(1000, 128, input_shape = (1000, )),\n",
    "    Flatten(),\n",
    "    Dense(128, activation = 'relu'),\n",
    "    Dense(64, activation = 'relu'),\n",
    "    Dense(7, activation = 'softmax')\n",
    "])\n",
    "\n",
    "# print model summary\n",
    "model2.summary()\n",
    "\n",
    "# define F1 metric\n",
    "f1_score_metric = F1Score(num_classes = 7, average = 'weighted')\n",
    "\n",
    "# compile model\n",
    "model2.compile(optimizer = 'rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy', f1_score_metric])\n",
    "    \n",
    "# define early stopping criterion\n",
    "early = EarlyStopping(monitor = 'f1_score', mode = 'max', patience = 3)\n",
    "\n",
    "# train deep learning model\n",
    "trained2 = model2.fit(trainDFtextVec1000,\n",
    "                      to_categorical(trainDF['Cat_code']),\n",
    "                      epochs = 100,\n",
    "                      batch_size = 32,\n",
    "                      callbacks = early,\n",
    "                      verbose = 1)\n",
    "\n",
    "# predict on test set\n",
    "pred2 = model2.predict(testDFtextVec1000)\n",
    "\n",
    "# create submission data frame\n",
    "submission = pd.DataFrame({'Id': testDF['Id'], 'Cat_code': np.argmax(pred2, axis = 1).reshape(len(pred2), )})\n",
    "\n",
    "# export submission\n",
    "submission.to_csv('./submission2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
